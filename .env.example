# OpenAI API Configuration (Optional - Automatic Fallback)
# ============================================================
# The agentic team discussions can use either OpenAI or local Ollama models.
#
# AUTOMATIC FALLBACK TO OLLAMA:
# If no valid OpenAI API key is configured, the system automatically falls back
# to using the local Ollama model (tinyllama:latest). This allows the application
# to work seamlessly in offline environments without any code changes.
#
# To use OpenAI (recommended for production):
# 1. Get your API key from: https://platform.openai.com/api-keys
# 2. Replace "your_openai_api_key_here" with your actual key
# 3. Restart the backend: docker compose restart backend
#
# To use Ollama only (offline mode):
# - Simply leave the key as-is or don't create a .env file
# - The system will automatically use local Ollama
OPENAI_API_KEY=your_openai_api_key_here

# Optional: Specify which OpenAI model to use (default: gpt-4o-mini for speed and cost)
# Options: gpt-4o-mini (recommended), gpt-4o, gpt-3.5-turbo
OPENAI_MODEL=gpt-4o-mini
